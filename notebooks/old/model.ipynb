{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class VariableSizeCNN(nn.Module):\n",
    "    def __init__(self, max_grid_size=50, latent_dim=128, num_channels=16):\n",
    "        super(VariableSizeCNN, self).__init__()\n",
    "        self.max_grid_size = max_grid_size\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_channels = num_channels\n",
    "\n",
    "        # Encoder (CNN)\n",
    "        self.conv1 = nn.Conv2d(1, num_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(num_channels, num_channels*2, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(num_channels*2, num_channels*4, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Global Average Pooling to get fixed-size latent representation\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        # Fully connected layer to generate latent representation\n",
    "        self.fc1 = nn.Linear(num_channels*4, latent_dim)\n",
    "        \n",
    "        # Decoder (Fully connected layers to generate output parameters)\n",
    "        self.fc2 = nn.Linear(latent_dim, max_grid_size * max_grid_size)\n",
    "        self.fc3 = nn.Linear(latent_dim, 10)  # Assuming max 10 unique values in output\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Get input size\n",
    "        _, _, h, w = x.size()\n",
    "        \n",
    "        # Encoder\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        \n",
    "        # Global Average Pooling\n",
    "        x = self.gap(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Generate latent representation\n",
    "        latent = self.fc1(x)\n",
    "        \n",
    "        # Decoder\n",
    "        output_values = torch.sigmoid(self.fc3(latent))  # Sigmoid to keep values between 0 and 1\n",
    "        output_mask = self.fc2(latent).view(-1, 1, self.max_grid_size, self.max_grid_size)\n",
    "        output_mask = output_mask[:, :, :h, :w]  # Crop to input size\n",
    "        \n",
    "        # Generate output\n",
    "        output = torch.matmul(output_mask.view(-1, h*w, 1), output_values.unsqueeze(1))\n",
    "        output = output.view(-1, 1, h, w)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Usage example\n",
    "model = VariableSizeCNN()\n",
    "\n",
    "# Example input (batch_size=1, channels=1, height=10, width=10)\n",
    "x = torch.randn(1, 1, 10, 10)\n",
    "\n",
    "output = model(x)\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
