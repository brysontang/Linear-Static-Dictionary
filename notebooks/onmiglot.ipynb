{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import learn2learn as l2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_background.zip to data/omniglot-py/images_background.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.46M/9.46M [00:00<00:00, 41.7MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/omniglot-py/images_background.zip to data/omniglot-py\n",
      "Downloading https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_evaluation.zip to data/omniglot-py/images_evaluation.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.46M/6.46M [00:00<00:00, 33.2MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/omniglot-py/images_evaluation.zip to data/omniglot-py\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "# 1. Data Loading via learn2learn\n",
    "############################\n",
    "N_WAY = 5\n",
    "K_SHOT = 1\n",
    "Q_QUERY = 5\n",
    "\n",
    "tasksets = l2l.vision.benchmarks.get_tasksets(\n",
    "    \"omniglot\",\n",
    "    train_ways=N_WAY,\n",
    "    train_samples=K_SHOT+Q_QUERY,\n",
    "    test_ways=N_WAY,\n",
    "    test_samples=K_SHOT+Q_QUERY,\n",
    "    num_tasks=20000,  \n",
    "    root='data',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "# 2. Model Definition\n",
    "############################\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, output_size=64):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Padding to maintain spatial dims before pooling\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.fc = nn.Linear(64*1*1, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (B,1,28,28)\n",
    "        x = F.relu(self.pool(self.conv1(x))) # (B,64,14,14)\n",
    "        x = F.relu(self.pool(self.conv2(x))) # (B,64,7,7)\n",
    "        x = F.relu(self.pool(self.conv3(x))) # (B,64,3,3)\n",
    "        x = F.relu(self.pool(self.conv4(x))) # (B,64,1,1)\n",
    "        x = x.view(x.size(0), -1) # (B,64)\n",
    "        x = self.fc(x) # (B,64)\n",
    "        return x\n",
    "\n",
    "feature_extractor = SimpleCNN().to(device)\n",
    "\n",
    "def init_memory():\n",
    "    return nn.Parameter(torch.zeros(N_WAY, 64, device=device))\n",
    "\n",
    "def classify_with_memory(embeddings, memory):\n",
    "    return torch.matmul(embeddings, memory.t())  # (B,N_WAY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "# 3. Optimizer\n",
    "############################\n",
    "outer_optimizer = optim.Adam(feature_extractor.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-step 0: Query Loss = 1.6482\n",
      "Meta-step 1: Query Loss = 1.6379\n",
      "Meta-step 2: Query Loss = 1.6319\n",
      "Meta-step 3: Query Loss = 1.6287\n",
      "Meta-step 4: Query Loss = 1.6264\n",
      "Meta-step 5: Query Loss = 1.6228\n",
      "Meta-step 6: Query Loss = 1.6217\n",
      "Meta-step 7: Query Loss = 1.6203\n",
      "Meta-step 8: Query Loss = 1.6171\n",
      "Meta-step 9: Query Loss = 1.6160\n",
      "Meta-step 10: Query Loss = 1.6150\n",
      "Meta-step 11: Query Loss = 1.6142\n",
      "Meta-step 12: Query Loss = 1.6133\n",
      "Meta-step 13: Query Loss = 1.6123\n",
      "Meta-step 14: Query Loss = 1.6119\n",
      "Meta-step 15: Query Loss = 1.6112\n",
      "Meta-step 16: Query Loss = 1.6112\n",
      "Meta-step 17: Query Loss = 1.6107\n",
      "Meta-step 18: Query Loss = 1.6104\n",
      "Meta-step 19: Query Loss = 1.6102\n",
      "Meta-step 20: Query Loss = 1.6099\n",
      "Meta-step 21: Query Loss = 1.6100\n",
      "Meta-step 22: Query Loss = 1.6101\n",
      "Meta-step 23: Query Loss = 1.6099\n",
      "Meta-step 24: Query Loss = 1.6099\n",
      "Meta-step 25: Query Loss = 1.6096\n",
      "Meta-step 26: Query Loss = 1.6094\n",
      "Meta-step 27: Query Loss = 1.6111\n",
      "Meta-step 28: Query Loss = 1.6095\n",
      "Meta-step 29: Query Loss = 1.6097\n",
      "Meta-step 30: Query Loss = 1.6098\n",
      "Meta-step 31: Query Loss = 1.6099\n",
      "Meta-step 32: Query Loss = 1.6098\n",
      "Meta-step 33: Query Loss = 1.6097\n",
      "Meta-step 34: Query Loss = 1.6097\n",
      "Meta-step 35: Query Loss = 1.6098\n",
      "Meta-step 36: Query Loss = 1.6098\n",
      "Meta-step 37: Query Loss = 1.6096\n",
      "Meta-step 38: Query Loss = 1.6095\n",
      "Meta-step 39: Query Loss = 1.6096\n",
      "Meta-step 40: Query Loss = 1.6094\n",
      "Meta-step 41: Query Loss = 1.6094\n",
      "Meta-step 42: Query Loss = 1.6107\n",
      "Meta-step 43: Query Loss = 1.6098\n",
      "Meta-step 44: Query Loss = 1.6094\n",
      "Meta-step 45: Query Loss = 1.6099\n",
      "Meta-step 46: Query Loss = 1.6094\n",
      "Meta-step 47: Query Loss = 1.6095\n",
      "Meta-step 48: Query Loss = 1.6095\n",
      "Meta-step 49: Query Loss = 1.6095\n",
      "Meta-step 50: Query Loss = 1.6094\n",
      "Meta-step 51: Query Loss = 1.6094\n",
      "Meta-step 52: Query Loss = 1.6094\n",
      "Meta-step 53: Query Loss = 1.6097\n",
      "Meta-step 54: Query Loss = 1.6095\n",
      "Meta-step 55: Query Loss = 1.6101\n",
      "Meta-step 56: Query Loss = 1.6094\n",
      "Meta-step 57: Query Loss = 1.6098\n",
      "Meta-step 58: Query Loss = 1.6092\n",
      "Meta-step 59: Query Loss = 1.6099\n",
      "Meta-step 60: Query Loss = 1.6108\n",
      "Meta-step 61: Query Loss = 1.6096\n",
      "Meta-step 62: Query Loss = 1.6101\n",
      "Meta-step 63: Query Loss = 1.6098\n",
      "Meta-step 64: Query Loss = 1.6109\n",
      "Meta-step 65: Query Loss = 1.6095\n",
      "Meta-step 66: Query Loss = 1.6096\n",
      "Meta-step 67: Query Loss = 1.6094\n",
      "Meta-step 68: Query Loss = 1.6090\n",
      "Meta-step 69: Query Loss = 1.6109\n",
      "Meta-step 70: Query Loss = 1.6098\n",
      "Meta-step 71: Query Loss = 1.6095\n",
      "Meta-step 72: Query Loss = 1.6094\n",
      "Meta-step 73: Query Loss = 1.6095\n",
      "Meta-step 74: Query Loss = 1.6098\n",
      "Meta-step 75: Query Loss = 1.6099\n",
      "Meta-step 76: Query Loss = 1.6095\n",
      "Meta-step 77: Query Loss = 1.6091\n",
      "Meta-step 78: Query Loss = 1.6096\n",
      "Meta-step 79: Query Loss = 1.6093\n",
      "Meta-step 80: Query Loss = 1.6097\n",
      "Meta-step 81: Query Loss = 1.6095\n",
      "Meta-step 82: Query Loss = 1.6094\n",
      "Meta-step 83: Query Loss = 1.6095\n",
      "Meta-step 84: Query Loss = 1.6117\n",
      "Meta-step 85: Query Loss = 1.6099\n",
      "Meta-step 86: Query Loss = 1.6096\n",
      "Meta-step 87: Query Loss = 1.6100\n",
      "Meta-step 88: Query Loss = 1.6102\n",
      "Meta-step 89: Query Loss = 1.6098\n",
      "Meta-step 90: Query Loss = 1.6102\n",
      "Meta-step 91: Query Loss = 1.6096\n",
      "Meta-step 92: Query Loss = 1.6089\n",
      "Meta-step 93: Query Loss = 1.6120\n",
      "Meta-step 94: Query Loss = 1.6108\n",
      "Meta-step 95: Query Loss = 1.6098\n",
      "Meta-step 96: Query Loss = 1.6093\n",
      "Meta-step 97: Query Loss = 1.6099\n",
      "Meta-step 98: Query Loss = 1.6095\n",
      "Meta-step 99: Query Loss = 1.6095\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "# 4. Training Loop\n",
    "############################\n",
    "feature_extractor.train()\n",
    "inner_steps = 5\n",
    "inner_lr = 0.1\n",
    "meta_batches = 100\n",
    "\n",
    "for meta_step in range(meta_batches):\n",
    "    task = tasksets.train.sample()\n",
    "    X, Y = task  # X.shape: [N_WAY*(K_SHOT+Q_QUERY), 1,28,28], Y.shape: [N_WAY*(K_SHOT+Q_QUERY)]\n",
    "\n",
    "    support_count = N_WAY * K_SHOT\n",
    "    query_count = N_WAY * Q_QUERY\n",
    "\n",
    "    support_x = X[:support_count]\n",
    "    support_y = Y[:support_count]\n",
    "    query_x = X[support_count:support_count+query_count]\n",
    "    query_y = Y[support_count:support_count+query_count]\n",
    "\n",
    "    memory = init_memory()\n",
    "    memory.requires_grad = True\n",
    "\n",
    "    inner_optimizer = torch.optim.SGD([memory], lr=inner_lr)\n",
    "    for _ in range(inner_steps):\n",
    "        sup_feat = feature_extractor(support_x)\n",
    "        sup_logits = classify_with_memory(sup_feat, memory)\n",
    "        sup_loss = F.cross_entropy(sup_logits, support_y)\n",
    "\n",
    "        inner_optimizer.zero_grad()\n",
    "        sup_loss.backward()\n",
    "        inner_optimizer.step()\n",
    "\n",
    "    que_feat = feature_extractor(query_x)\n",
    "    que_logits = classify_with_memory(que_feat, memory)\n",
    "    que_loss = F.cross_entropy(que_logits, query_y)\n",
    "\n",
    "    outer_optimizer.zero_grad()\n",
    "    que_loss.backward()\n",
    "    outer_optimizer.step()\n",
    "\n",
    "    print(f\"Meta-step {meta_step}: Query Loss = {que_loss.item():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
